# -*- coding: utf-8 -*-
"""CCTV_RTSP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12NiD1glrQmxvr8upV9xNPthzc92wdzuv
"""

from google.colab import drive
drive.mount('/content/gdrive')

pip install opencv-python

import cv2
import numpy as np
from threading import Thread

# Define placeholder video paths (replace with your actual paths)
video_paths = ["/content/gdrive/MyDrive/ppe/images/store-aisle-detection.mp4","/content/gdrive/MyDrive/ppe/images/classroom.mp4","/content/gdrive/MyDrive/ppe/images/face-demographics-walking.mp4"]

# Simple person detection using Haar Cascade classifier
haar_cascade = cv2.CascadeClassifier("/content/gdrive/MyDrive/ppe/images/haarcascade_frontalface_default.xml")

def process_camera(cap, video_path):
  # Define output video writer
  out = cv2.VideoWriter(f"output_{video_path.split('/')[-1]}",
                        cv2.VideoWriter_fourcc(*'XVID'),
                        cap.get(cv2.CAP_PROP_FPS),
                        (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                         int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))

  # Define frame count for 20 seconds of video
  frame_count = int(cap.get(cv2.CAP_PROP_FPS) * 20)

  # Process video frames
  while frame_count > 0:
    ret, frame = cap.read()
    if not ret:
      break

    # Convert to grayscale
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect people
    people = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

    # Overlay detections
    for (x, y, w, h) in people:
      cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)

    # Write frame to output video
    out.write(frame)
    frame_count -= 1

  # Release resources
  cap.release()
  out.release()

if __name__ == "__main__":
  threads = []

  # Open video capture objects (replace with cv2.VideoCapture(rtsp_url) for real cameras)
  caps = [cv2.VideoCapture(path) for path in video_paths]

  # Start processing threads
  for i, cap in enumerate(caps):
    thread = Thread(target=process_camera, args=(cap, video_paths[i]))
    thread.start()
    threads.append(thread)

  # Wait for threads to finish
  for thread in threads:
    thread.join()

  print("All videos processed!")